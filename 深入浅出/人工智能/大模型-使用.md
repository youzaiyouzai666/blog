# 什么场景下使用 AI

[使用 AI 前需要评估的](https://easyaitech.medium.com/41%E9%A1%B5pdf%E5%85%8D%E8%B4%B9%E4%B8%8B-%E4%BD%BF%E7%94%A8ai%E5%89%8D%E9%9C%80%E8%A6%81%E8%AF%84%E4%BC%B0%E7%9A%84-e13ccc0734e1)

精度：[Atom Capital：AI 是泡沫吗？](https://mp.weixin.qq.com/s/Fy3Dxd1wAzNtdzFyenZu4w)
遇到瓶颈： 现在 还没有发现有现象级应用及商业模式的出现；而且技术也遇到瓶颈了，尤其是深度学习领域。

# 名词解释

## 拟合&泛化

拟合（Fitting）和泛化（Generalization）是机器学习和统计建模中的两个重要概念。这两个概念之间的平衡是构建模型时需要考虑的关键问题。

#### a.拟合（Fitting）

拟合是指模型在训练数据上的表现。一个模型的拟合能力越强，它在训练数据上的预测误差就越小。具体地说，拟合可以分为两种情况：

1. **欠拟合（Underfitting）**：模型过于简单，无法捕捉数据的基本模式。这通常会导致训练误差和测试误差都比较高。

2. **过拟合（Overfitting）**：模型过于复杂，过分依赖于训练数据中的噪声或细节。这通常会导致训练误差较低，但测试误差较高，因为模型在未见过的数据上表现不好。

#### b.泛化（Generalization）

泛化是指模型在新数据（通常叫测试数据或验证数据）上的表现能力。一个好的模型应具备良好的泛化能力，能够在未见过的数据上依然保持较高的准确率。泛化能力通常通过以下方式来评估：

- **交叉验证（Cross-validation）**：将数据集分为多个部分（折），轮流使用其中一部分作为验证集来测试模型，其余作为训练集。

- **留出法（Hold-out method）**：将数据集分为训练集和测试集，在训练集上训练模型，然后在测试集上评估性能。

#### c.拟合与泛化的平衡

在实际应用中，找到一个既能很好地拟合训练数据，又能良好地泛化到新数据的模型是非常重要的。为了实现这一点，可以采取以下方法：

- **选择适当的模型复杂度**：根据数据集的特征和规模选择合适的模型。
- **正则化（Regularization）**：引入惩罚项来限制模型的复杂度，防止过拟合。
- **特征选择与降维**：减少输入特征的数量，使模型更简单，同时去除不必要的噪声。

总之，理解拟合和泛化的概念及其平衡对于构建有效的机器学习模型至关重要。

## 微调&预训练

## 大模型 agent 和 copilot 的区别

大模型 agent 和 copilot 的区别主要体现在交互方式、任务执行和独立性等方面。

交互方式：copilot 需要用户给出清晰明确的 prompt，即需要用户具体详细地描述任务或问题，copilot 才能根据 prompt 给出有用的回答。相比之下，大模型 agent 的交互方式更为灵活，它可以根据给定的目标自主思考并做出行动，无需用户给出过于详细明确的 prompt。

任务执行：copilot 在接收到清晰明确的 prompt 后，可以协助完成一些任务，但它的执行能力相对有限。而大模型 agent 则可以根据目标自主规划并执行任务，还能连接多种服务和工具来达成目标，执行任务的能力更强。

独立性：copilot 被视为一个“副驾驶”，在完成任务时更多的是起辅助作用，需要用户的引导。而大模型 agent 则更像一个初级的“主驾驶”，具有较强的独立性，可以根据目标自主思考和行动。

大模型 agent 和 copilot 的主要区别在于交互方式、任务执行和独立性。copilot 需要依赖清晰明确的 prompt 来发挥作用，而大模型 agent 则可以根据目标自主思考和行动，具有更强的独立性和任务执行能力。

## 提示工程 vs 预训练

提示工程和传统的模型微调主要区别在于预训练模型被修改的程度，模型微调修改模型的权重，而提示工程只修改模型的输入。因此，提示工程调整要比模型微调的投入成本更低，所需的资源和训练时间也更少。此外，提示工程还比模型微调更为灵活，因为它允许创建特定任务的提示，足以适应各种任务。最后，借助 检索增强生成（RAG）的方式，通过引入外部知识库等额外信息源，可以进一步提升提示工程的生成能力
检索增强生成

| 技术方案     | 上手难度                       | 资源成本                             | 定制能力                   | 数据要求                       | 更新频率                           | 模型微调                       |
| ------------ | ------------------------------ | ------------------------------------ | -------------------------- | ------------------------------ | ---------------------------------- | ------------------------------ |
| 模型微调     | 高，掌握机器学习原理和模型架构 | 高，训练需要大量的计算资源           | 高，允许自由定制           | 高，需要大量高质量的训练数据集 | 低，需要重新训练模型               | 高，需要大量高质量的训练数据集 |
| 提示工程     | 低，学习如何构建 Prompt        | 低，使用现有模型，按需收费           | 低，受限于预训练模型       | 无                             | 低，取决于预训练模型的重新训练频率 | 无                             |
| 检索增强生成 | 中，了解信息检索的机制         | 中，比提示工程多出一些信息检索的费用 | 中，取决于提供的外部数据源 | 中，提供外部数据库或信息源     | 高，会随着外部数据的实时更新       | 中，提供外部数据库或信息源     |

# Langchain

[使用 Nodejs 和 Langchain 开发大模型](https://juejin.cn/post/7252605744255615035?searchId=20240914141454A4C2F19FB766B61BB76D)
[通义千问和 LangChain 搭建对话服务](https://help.aliyun.com/document_detail/2708788.html)
[github](https://github.com/langchain-ai/langchainjs)
[放弃 langchain](https://www.octomind.dev/blog/why-we-no-longer-use-langchain-for-building-our-ai-agents)

# 使用模型优化路径

[大语言模型优化方法简介：Prompt、RAG、Fine-tuning](https://www.cnblogs.com/ghj1976/p/17947589/da-yu-yan-mo-xing-you-hua-fang-fa)
![Alt text](img/model_optimize.png)
[面向大语言模型的检索增强生成技术：综述 [译]](https://baoyu.io/translations/ai-paper/2312.10997-retrieval-augmented-generation-for-large-language-models-a-survey)

## Prompt Engineering 提示词工程

提示词工程可以分三个层次：

标准提示词
Few-shot 少量示例提示词，通过提供少量的示例来让模型回答的更精准。
XoT 提示词，例如 CoT（思维链），ToT（思维树），参看 使用思维链写 Prompt
下面是一个 Few-shot prompt 的示例：

```
A "whatpu" is a small, furry animal native to Tanzania. An example of a sentence that uses
the word whatpu is:
“whatpu”是坦桑尼亚的一种小型毛茸茸的动物。一个使用whatpu这个词的句子的例子是：

We were traveling in Africa and we saw these very cute whatpus.
我们在非洲旅行时看到了这些非常可爱的whatpus。

To do a "farduddle" means to jump up and down really fast. An example of a sentence that uses the word farduddle is:
“farduddle”是指快速跳上跳下。一个使用farduddle这个词的句子的例子是：
```

输出：

```
When we won the game, we all started to farduddle in celebration.
当我们赢得比赛时，我们都开始庆祝跳跃。
```

## RAG 检索增强生成

[检索增强生成（Retrieval-Augmented Generation, RAG）](https://mp.weixin.qq.com/s/miZY_etpyqVofstr0chuOg) 特指一种模式：模型在回答问题或生成文本时，首先从广阔的文档库中寻找相关信息。然后，模型使用这些找到的信息来生成回答或文本，从而提高其预测的准确度。

论文中把 RAG 分成三种范式：

Naive RAG 朴素 RAG, 添加相关上下文
Advanced RAG 高级 RAG，在索引/检索前/检索后做优化
Modular RAG 模块化 RAG，有机组合多种模块
下图是三种 RAG 范式的比较

## Fine-tuning 微调

比 RAG 更复杂的就是微调了，微调方法是为了提高模型在特定任务上的表现，根据关注的焦点不同，分三种：

- 检索器微调专注于改进信息查找过程，
- 生成器微调专注于改进输出的质量，
- 协同微调则旨在优化这两个组件之间的协作。

### 1.Retriever Fine-tuning（检索器微调）

检索器是指模型中用来从大量数据中检索信息的部分，通常用于处理需要查找和利用外部知识的任务，如问答系统。

微调检索器就是对这部分模型进行特殊训练，使其更擅长从数据集中找到相关信息。

举个例子，就像在图书馆中训练一个图书管理员，使其更快地找到你需要的书。

### 2.Generator Fine-tuning（生成器微调）：

生成器是模型中负责产生响应或输出的部分，如文本生成模型中创建新文本的部分。

微调生成器意味着特别训练这个部分，使其在产生输出时更准确、更符合目标任务的要求。

例如，如果你想让模型写诗，你会特别训练它理解和使用诗歌的结构和韵律。

### 3.Collaborative Fine-tuning（协同微调）

这是一种更复杂的微调方法，涉及到模型中的检索器和生成器同时被调整，以更好地协同工作完成任务。

在协同微调过程中，检索器和生成器相互学习，以提高整体性能。检索器提供的信息可以帮助生成器产生更准确的输出，而生成器的需求可以引导检索器寻找更相关的信息。

可以想象成一个团队工作的情况，团队中的每个成员（检索器和生成器）都在相互学习，以更好地协作完成任务。

# Prompt 学习

[一文搞懂 Prompt Engineering](https://wuxinhua.com/posts/prompt-engineering/)

[提示工程指南](https://www.promptingguide.ai/zh)

[经典 Prompt 欣赏 - GitHub Copilot Chat](https://mp.weixin.qq.com/s?__biz=MzkwODQyMzczMg==&mid=2247485184&idx=1&sn=71c01815d54fae9a4a00cb34b4ffa5b3&chksm=c0cb605bf7bce94dd0739618cc10792b665ba8220480c863ea863e0d0cc4ce4a6d05897c405c&cur_album_id=3172141258211852289&scene=189#wechat_redirect)
